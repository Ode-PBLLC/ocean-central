{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3305cdea-4b0c-4b00-ab2e-357464bdd2eb",
   "metadata": {},
   "source": [
    "# Protect Marine Life"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412acc8-b9a5-48bf-a844-ef7d9310d75d",
   "metadata": {},
   "source": [
    "### This notebook outlines the general workflow for the data within the [Protect Marine Life](https://oceancentral.org/track/protect-marine-life) page of the Ocean Central website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84844fb5-f187-4a10-a7f8-ab28349679f7",
   "metadata": {},
   "source": [
    "# Overview Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540b7d5-943f-4a7c-9a52-9ac82be208e1",
   "metadata": {},
   "source": [
    "## Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c677ea7-9702-4973-a775-5c0accf0dad0",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_1.png\" style=\"width:50%;\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37a51e-a8de-4687-b853-7ac7cc38b905",
   "metadata": {},
   "source": [
    "The data are derived from the Marine populations dataset from [Living Planet Index](https://www.livingplanetindex.org/latest_results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7154802-b615-4e03-8300-a5451f6a99c9",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0ee35-2628-42af-b45d-3da4b72ff8e9",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_2.png\" style=\"width:50%;\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb478e1-f1e5-4a50-b45d-074e161e5644",
   "metadata": {},
   "source": [
    "The data are derived from [Rebuilding Marine Life](https://www.nature.com/articles/s41586-020-2146-7) -- Duarte et al. (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dbfc8-2aa2-4fe8-8976-c2af17c4242c",
   "metadata": {},
   "source": [
    "# IUCN Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d7e1d-d787-4c8a-a28f-5be37153a816",
   "metadata": {},
   "source": [
    "### This section contains code to get marine species, threats, and trends from the IUCN API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d361468-333a-4ff0-8072-0690508ca621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions and necessary packages\n",
    "\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pycountry\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "token = os.getenv(\"IUCN_API_KEY\")\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://api.iucnredlist.org/api/v4/habitats/\"\n",
    "\n",
    "# Set up the headers with the token\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": token\n",
    "}\n",
    "\n",
    "# Function to convert country code to country name\n",
    "def get_country_name(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).name\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Function to get assessments for a given habitat\n",
    "def get_assessments(habitat_id):\n",
    "    page = 1\n",
    "    per_page = 100\n",
    "    assessments = []\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Habitat: {habitat_id}, Page: {page}\")\n",
    "        # Construct the URL with pagination parameters\n",
    "        url = f\"{base_url}{habitat_id}?page={page}&per_page={per_page}\"\n",
    "        \n",
    "        # Make the GET request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            assessments.extend(data.get('assessments', []))\n",
    "            \n",
    "            # Check if we have reached the last page\n",
    "            total_pages = int(response.headers.get('total-pages', 1))\n",
    "            if page >= total_pages:\n",
    "                break\n",
    "            \n",
    "            # Move to the next page\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for habitat {habitat_id}: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "            \n",
    "    return assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd4fc6-514e-4dfd-9326-24aaa24a43c8",
   "metadata": {},
   "source": [
    "**This code block below gets all marine species assessments (with the habitat codes 9, 10, 11, 12, or 13 corresponding to marine species). The species (sis_taxon_id) and assessment (assessment_id) IDs will be used for the code to generate all of the figures.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0640b-6f7d-45fb-b123-8ff798eaf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../Data/marine_habitats.csv\"):\n",
    "    # Initialize variables for storing all assessments\n",
    "    all_assessments = []\n",
    "    \n",
    "    # Iterate through major categories and their subcategories\n",
    "    major_habitats = [9, 10, 11, 12, 13]\n",
    "    for habitat_id in major_habitats:\n",
    "        # Get assessments for the main category\n",
    "        all_assessments.extend(get_assessments(habitat_id))\n",
    "        \n",
    "        # Check for subcategories (assuming subcategories range from 1 to 15)\n",
    "        for sub_id in range(1, 16):\n",
    "            sub_habitat_id = f\"{habitat_id}_{sub_id}\"\n",
    "            all_assessments.extend(get_assessments(sub_habitat_id))\n",
    "    \n",
    "    # Extract relevant information for each assessment\n",
    "    rows = []\n",
    "    for assessment in all_assessments:\n",
    "        row = {\n",
    "            \"year_published\": assessment.get(\"year_published\"),\n",
    "            \"latest\": assessment.get(\"latest\"),\n",
    "            \"sis_taxon_id\": assessment.get(\"sis_taxon_id\"),\n",
    "            \"url\": assessment.get(\"url\"),\n",
    "            \"assessment_id\": assessment.get(\"assessment_id\"),\n",
    "            \"code\": assessment.get(\"code\"),\n",
    "            \"code_type\": assessment.get(\"code_type\"),\n",
    "            \"scope_description\": assessment.get(\"scopes\")[0].get(\"description\").get(\"en\") if assessment.get(\"scopes\") else None,\n",
    "            \"scope_code\": assessment.get(\"scopes\")[0].get(\"code\") if assessment.get(\"scopes\") else None,\n",
    "            \"habitat_id\": assessment.get(\"habitat_id\"),  # Add habitat_id to the row\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    marine_df = pd.DataFrame(rows)\n",
    "    marine_df.to_csv(\"../Data/marine_habitats.csv\")\n",
    "    marine_df\n",
    "else:\n",
    "    marine_df = pd.read_csv(\"../Data/marine_habitats.csv\")\n",
    "    marine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fc039-f1ea-4d36-8559-2adb55984447",
   "metadata": {},
   "source": [
    "**This code block below gets threats and trends for all assessments IDs for marine species defined in the block above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5daa9-8160-4c82-b6f1-560b9e7fdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.iucnredlist.org/api/v4/assessment\"\n",
    "\n",
    "assessements_list = marine_df.loc[marine_df.groupby('sis_taxon_id')['year_published'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# List of assessment IDs\n",
    "assessment_ids = assessements_list['assessment_id'].dropna().astype(int).values\n",
    "\n",
    "# Initialize empty lists to hold all the data if not already defined\n",
    "try:\n",
    "    all_data\n",
    "except NameError:\n",
    "    all_data = []\n",
    "\n",
    "try:\n",
    "    all_data_threats\n",
    "except NameError:\n",
    "    all_data_threats = []\n",
    "\n",
    "# Extract processed assessment_ids from all_data\n",
    "processed_assessment_ids = {entry[\"assessment_id\"] for entry in all_data}\n",
    "\n",
    "def fetch_data_with_retry(url, headers, retries=5, backoff_factor=0.5):\n",
    "    for i in range(retries):\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 429:\n",
    "            wait_time = backoff_factor * (2 ** i)\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "if not os.path.exists(\"../Data/all_threats_species.csv\"):\n",
    "    for assessment_id in tqdm(assessment_ids):\n",
    "        # Skip if the assessment_id is already processed\n",
    "        if assessment_id in processed_assessment_ids:\n",
    "            continue\n",
    "    \n",
    "        # Construct the URL for the current assessment ID\n",
    "        url = f\"{base_url}/{assessment_id}\"\n",
    "        \n",
    "        # Fetch the data with retry mechanism\n",
    "        data = fetch_data_with_retry(url, headers)\n",
    "        \n",
    "        if data:\n",
    "            trend = data.get(\"population_trend\") if data.get(\"population_trend\") is None else data.get(\"population_trend\").get(\"code\")\n",
    "            class_name = data.get(\"taxon\", {}).get(\"class_name\")\n",
    "            sis_taxon_id = data.get(\"sis_taxon_id\", [])\n",
    "            locations = data.get(\"locations\", [])\n",
    "            threats = data.get(\"threats\", [])\n",
    "            status = data.get(\"red_list_category\", {}).get(\"code\")\n",
    "            year_published = data.get(\"year_published\", [])\n",
    "    \n",
    "            # Extract the common English name (if available)\n",
    "            common_names = data.get(\"taxon\", {}).get(\"common_names\", [])\n",
    "            english_common_name = next(\n",
    "                (name[\"name\"] for name in common_names if name.get(\"language\") == \"eng\"),\n",
    "                None\n",
    "            )\n",
    "\n",
    "            \n",
    "            # Add the assessment data to the list\n",
    "            for location in locations:\n",
    "                country_code = location.get(\"code\")\n",
    "                assessment_data = {\n",
    "                    \"assessment_id\": assessment_id,\n",
    "                    \"sis_taxon_id\": sis_taxon_id,\n",
    "                    \"country_code\": country_code,\n",
    "                    \"trend\": trend,\n",
    "                    \"class_name\": class_name,\n",
    "                    \"status\": status,\n",
    "                    \"year_published\": year_published,\n",
    "                    \"english_common_name\": english_common_name  # Store the common English name here\n",
    "                }\n",
    "                all_data.append(assessment_data)\n",
    "    \n",
    "            # Add the threats data to the list\n",
    "            for location in locations:\n",
    "                country_code = location.get(\"code\")\n",
    "                for threat in threats:\n",
    "                    threat_code = threat.get(\"code\")\n",
    "                    threat_data = {\n",
    "                        \"assessment_id\": assessment_id,\n",
    "                        \"sis_taxon_id\": sis_taxon_id,\n",
    "                        \"country_code\": country_code,\n",
    "                        \"threat_code\": threat_code,\n",
    "                        \"class_name\": class_name,\n",
    "                        \"year_published\": year_published,\n",
    "                        \"english_common_name\": english_common_name  # Store the common English name here\n",
    "                    }\n",
    "                    all_data_threats.append(threat_data)\n",
    "            \n",
    "            # Mark the assessment_id as processed\n",
    "            processed_assessment_ids.add(assessment_id)\n",
    "    \n",
    "    # Create DataFrames from the collected data\n",
    "    trends_df = pd.DataFrame(all_data)\n",
    "    threats_df = pd.DataFrame(all_data_threats)\n",
    "    trends_df.to_csv(\"../Data/all_trends_species.csv\")\n",
    "    threats_df.to_csv(\"../Data/all_threats_species.csv\")\n",
    "else:\n",
    "    trends_df = pd.read_csv(\"../Data/all_trends_species.csv\")\n",
    "    threats_df = pd.read_csv(\"../Data/all_threats_species.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93e2b8-33e0-4837-92b0-4eeb68652889",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce59464-1ec6-4fc0-b6bd-899956d7fbe1",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_3.png\" style=\"width:50%;\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f3a7a-5755-49d9-ab64-a88e4586cf76",
   "metadata": {},
   "source": [
    "**This code iterates through each species over time, and if a species does not have an assessment for a given year, it assigns that species-year combination the most recent assessment's trend for that species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9838dc1-380d-40ad-b017-6dff8650f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df = trends_df[[\"assessment_id\",\"year_published\",\"sis_taxon_id\",\"country_code\",\"status\",\"class_name\",\"english_common_name\",\"trend\"]]#.merge(df_unique[[\"assessment_id\",\"year_published\",\"sis_taxon_id\"]], on=\"assessment_id\", how=\"inner\")\n",
    "trends_df['year_published'] = trends_df['year_published'].astype(int)\n",
    "\n",
    "# Mapping dictionary\n",
    "threats_mapping = {\n",
    "    'DD': 'Data Deficient',\n",
    "    'LC': 'Least Concern',\n",
    "    'NT': 'Near Threatened',\n",
    "    'VU': 'Vulnerable',\n",
    "    'EN': 'Endangered',\n",
    "    'CR': 'Critically Endangered',\n",
    "    'EW': 'Extinct in the Wild',\n",
    "    'EX': 'Extinct',\n",
    "    'NE': 'Not Evaluated',\n",
    "}\n",
    "\n",
    "# Replace the values in the 'Threat' column\n",
    "trends_df['Threat'] = trends_df['status'].replace(threats_mapping)\n",
    "\n",
    "trends_df.loc[trends_df[\"trend\"] == 0, 'trend_title'] = \"Increasing\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 1, 'trend_title'] = \"Decreasing\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 2, 'trend_title'] = \"Stable\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 3, 'trend_title'] = \"Unknown\"\n",
    "\n",
    "# Initialize an empty list to store new rows\n",
    "new_rows = []\n",
    "\n",
    "# Define the range of years\n",
    "years = range(1997, 2026)\n",
    "\n",
    "# Iterate through each sis_taxon_id\n",
    "for sis_taxon_id in tqdm(trends_df['sis_taxon_id'].unique()):\n",
    "    # Filter data for the current sis_taxon_id\n",
    "    df_sis = trends_df[trends_df['sis_taxon_id'] == sis_taxon_id]\n",
    "    \n",
    "    # Iterate through each year in the defined range\n",
    "    for year in years:\n",
    "        # Check if there is an entry for the current year\n",
    "        if year not in df_sis['year_published'].values:\n",
    "            # Find the most recent threat categorization from a previous year\n",
    "            previous_threats = df_sis[df_sis['year_published'] < year]\n",
    "            if not previous_threats.empty:\n",
    "                last_threat = previous_threats.iloc[-1]['Threat']\n",
    "                class_name = previous_threats.iloc[-1]['class_name']\n",
    "                country_code = previous_threats.iloc[-1]['country_code']\n",
    "                english_common_name = previous_threats.iloc[-1]['english_common_name']\n",
    "                trend_title = previous_threats.iloc[-1]['trend_title']\n",
    "                # Create a new row with the current year, sis_taxon_id, and the most recent threat categorization\n",
    "                new_row = {\n",
    "                    'year_published': year,\n",
    "                    'Threat': last_threat,\n",
    "                    'sis_taxon_id': sis_taxon_id,\n",
    "                    'class_name': class_name,\n",
    "                    \"country_code\": country_code,\n",
    "                    \"english_common_name\": english_common_name,\n",
    "                    \"trend_title\": trend_title,\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "# Create a DataFrame from the new rows\n",
    "df_new_rows = pd.DataFrame(new_rows)\n",
    "\n",
    "# Append the new rows to the original dataframe\n",
    "df_combined = pd.concat([trends_df, df_new_rows])\n",
    "\n",
    "# Sort the combined dataframe\n",
    "df_combined = df_combined.sort_values(by=['sis_taxon_id', 'year_published']).reset_index(drop=True)\n",
    "\n",
    "# Apply the function to the country_code column\n",
    "df_combined['country_name'] = df_combined['country_code'].apply(get_country_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128db845-6c35-4b54-959c-649dc3b8e2ef",
   "metadata": {},
   "source": [
    "**We then translate from scientific classnames to general categories (fish, mammals, reptiles, and birds). We also filter only to species with a threat level of \"Endangered\" or worse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dcf6f-69d8-4be6-a23c-fa049926cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping\n",
    "class_to_category = {\n",
    "    'ACTINOPTERYGII': 'Fish', \n",
    "    'CHONDRICHTHYES': 'Fish', \n",
    "    'SARCOPTERYGII': 'Fish', \n",
    "    'PETROMYZONTI': 'Fish',\n",
    "    'MYXINI': 'Fish',\n",
    "    'CEPHALASPIDOMORPHI': 'Fish',\n",
    "    'MAMMALIA': 'Mammals', \n",
    "    'REPTILIA': 'Reptiles', \n",
    "    'AVES': 'Birds'\n",
    "}\n",
    "\n",
    "df_combined = df_combined.drop_duplicates([\"sis_taxon_id\",\"year_published\"]).merge(marine_df.drop_duplicates(\"sis_taxon_id\")[[\"sis_taxon_id\"]],on='sis_taxon_id',how='inner')\n",
    "\n",
    "# Map the class names to categories\n",
    "df_combined['category'] = df_combined['class_name'].map(class_to_category)\n",
    "\n",
    "# Remove rows where category is NaN (those not in the specified classes)\n",
    "df_combined = df_combined.dropna(subset=['category'])\n",
    "\n",
    "# Create a pivot table for the total counts of species across all years and categories\n",
    "pivot_total = df_combined.pivot_table(index='year_published', columns='category', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Filter the data for specific threats\n",
    "filtered_df = df_combined[df_combined['Threat'].isin(['Critically Endangered', 'Endangered', 'Extinct in the Wild'])]\n",
    "\n",
    "# Create a pivot table for the filtered (threatened) species\n",
    "pivot_filtered = filtered_df.pivot_table(index='year_published', columns='category', aggfunc='size', fill_value=0)\n",
    "\n",
    "pivot_filtered = pivot_filtered.query(\"year_published > 2009\")\n",
    "pivot_total = pivot_total.query(\"year_published > 2009\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a33268-aa15-4467-b144-20ce16d0fa72",
   "metadata": {},
   "source": [
    "**We then calculate the percentage of species that are threatened (Endangered or worse) to all species assessed over time. This information will be used in Figure 3 of the Protect Marine Life section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578462f4-94a9-4899-8402-f7992247baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threats of interest\n",
    "threat_levels = ['Critically Endangered', 'Endangered', 'Extinct in the Wild']\n",
    "\n",
    "X_years = pivot_filtered.reset_index()[\"year_published\"].values.reshape([-1, 1])\n",
    "\n",
    "# Define a function to compute the linear trend for a given species category\n",
    "def compute_trend(species, pivot_filtered, pivot_total, X_years):\n",
    "    # Calculate the percentage and count for the given species\n",
    "    y_percents = pivot_filtered[species].values / pivot_total[species].values\n",
    "    y_counts = pivot_total[species].values\n",
    "    \n",
    "    # Filter out rows where y_percents or y_counts are NaN\n",
    "    mask = ~np.isnan(y_percents) & ~np.isnan(y_counts)\n",
    "    X_filtered = X_years[mask]\n",
    "    y_percents_filtered = y_percents[mask]\n",
    "    y_counts_filtered = y_counts[mask]\n",
    "    \n",
    "    # Initialize and fit the linear regression model on filtered data\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_filtered, y_percents_filtered, sample_weight=y_counts_filtered)\n",
    "    \n",
    "    # Predict using the full X_years, but only return the valid predictions\n",
    "    y_pred = np.full_like(y_percents, np.nan, dtype=np.float64)  # Initialize with NaN\n",
    "    y_pred[mask] = linear_model.predict(X_filtered)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "pivot_percents = pivot_filtered/pivot_total\n",
    "\n",
    "# Initialize an empty DataFrame to hold counts by threat level for each category\n",
    "pivot_threat_total = df_combined[df_combined['Threat'].isin(threat_levels)].pivot_table(\n",
    "    index='year_published', \n",
    "    columns='category', \n",
    "    aggfunc='size', \n",
    "    fill_value=0\n",
    ").query(\"year_published > 2009\")\n",
    "\n",
    "# Calculate individual trends for Birds, Fish, Mammals, and Reptiles, considering all threat levels\n",
    "pivot_percents['Bird_Linear_Trend'] = compute_trend(\"Birds\", pivot_threat_total, pivot_total, X_years)\n",
    "pivot_percents['Fish_Linear_Trend'] = compute_trend(\"Fish\", pivot_threat_total, pivot_total, X_years)\n",
    "pivot_percents['Mammal_Linear_Trend'] = compute_trend(\"Mammals\", pivot_threat_total, pivot_total, X_years)\n",
    "pivot_percents['Reptile_Linear_Trend'] = compute_trend(\"Reptiles\", pivot_threat_total, pivot_total, X_years)\n",
    "\n",
    "# Calculate the overall trend for all categories combined\n",
    "y_percents_all = (pivot_threat_total[\"Birds\"] + pivot_threat_total[\"Fish\"] + \n",
    "                  pivot_threat_total[\"Mammals\"] + pivot_threat_total[\"Reptiles\"]).values / \\\n",
    "                 (pivot_total[\"Birds\"] + pivot_total[\"Fish\"] + pivot_total[\"Mammals\"] + pivot_total[\"Reptiles\"]).values\n",
    "y_counts_all = (pivot_total[\"Birds\"] + pivot_total[\"Fish\"] + pivot_total[\"Mammals\"] + pivot_total[\"Reptiles\"]).values\n",
    "\n",
    "# Filter out NaNs for the overall trend\n",
    "mask_all = ~np.isnan(y_percents_all) & ~np.isnan(y_counts_all)\n",
    "X_filtered_all = X_years[mask_all]\n",
    "y_percents_filtered_all = y_percents_all[mask_all]\n",
    "y_counts_filtered_all = y_counts_all[mask_all]\n",
    "\n",
    "# Fit the linear regression model for the overall trend\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_filtered_all, y_percents_filtered_all, sample_weight=y_counts_filtered_all)\n",
    "pivot_percents['All_Linear_Trend'] = np.full_like(y_percents_all, np.nan, dtype=np.float64)\n",
    "pivot_percents['All_Linear_Trend'][mask_all] = linear_model.predict(X_filtered_all)\n",
    "pivot_percents['All'] = y_percents_all\n",
    "\n",
    "# Define the threats of interest\n",
    "threat_levels = ['Critically Endangered', 'Endangered', 'Extinct in the Wild']\n",
    "\n",
    "# Initialize an empty dictionary to hold pivot tables by threat level\n",
    "pivot_by_threat = {}\n",
    "\n",
    "# Create pivot tables for each threat level by species category\n",
    "for threat in threat_levels:\n",
    "    filtered_df_threat = df_combined[df_combined['Threat'] == threat]\n",
    "    pivot_by_threat[threat] = filtered_df_threat.pivot_table(\n",
    "        index='year_published', \n",
    "        columns='category', \n",
    "        aggfunc='size', \n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "# Add threat percentages for each species and threat level\n",
    "for threat in threat_levels:\n",
    "    for species in [\"Birds\", \"Fish\", \"Mammals\", \"Reptiles\"]:\n",
    "        # Calculate the percentage of the species category for this threat level\n",
    "        try:\n",
    "            pivot_percents[f\"{species}_{threat}\"] = pivot_by_threat[threat][species] / pivot_total[species]\n",
    "        except:\n",
    "            pivot_percents[f\"{species}_{threat}\"] = 0\n",
    "\n",
    "# Fill any remaining missing values with 0 and save to CSV\n",
    "pivot_percents.reset_index()[[\n",
    "    'year_published', 'All_Linear_Trend', 'All', 'Bird_Linear_Trend', 'Birds', \n",
    "    'Fish_Linear_Trend', 'Fish', 'Mammal_Linear_Trend', 'Mammals', \n",
    "    'Reptile_Linear_Trend', 'Reptiles',\n",
    "    'Birds_Critically Endangered', 'Birds_Endangered', 'Birds_Extinct in the Wild',\n",
    "    'Fish_Critically Endangered', 'Fish_Endangered', 'Fish_Extinct in the Wild',\n",
    "    'Mammals_Critically Endangered', 'Mammals_Endangered', 'Mammals_Extinct in the Wild',\n",
    "    'Reptiles_Critically Endangered', 'Reptiles_Endangered', 'Reptiles_Extinct in the Wild'\n",
    "]].fillna(0).to_csv(\"../Data/protect_marine_life_1.csv\")\n",
    "\n",
    "subset = pivot_percents.reset_index()[[\n",
    "    'year_published', 'All_Linear_Trend', 'All', 'Bird_Linear_Trend', 'Birds', \n",
    "    'Fish_Linear_Trend', 'Fish', 'Mammal_Linear_Trend', 'Mammals', \n",
    "    'Reptile_Linear_Trend', 'Reptiles',\n",
    "    'Birds_Critically Endangered', 'Birds_Endangered', 'Birds_Extinct in the Wild',\n",
    "    'Fish_Critically Endangered', 'Fish_Endangered', 'Fish_Extinct in the Wild',\n",
    "    'Mammals_Critically Endangered', 'Mammals_Endangered', 'Mammals_Extinct in the Wild',\n",
    "    'Reptiles_Critically Endangered', 'Reptiles_Endangered', 'Reptiles_Extinct in the Wild'\n",
    "]].fillna(0)\n",
    "\n",
    "# Save as JSON\n",
    "subset.to_json(\"../Data/Figure_3.json\", orient=\"records\", indent=2)\n",
    "\n",
    "# Display the updated DataFrame with linear trends and threat percentages\n",
    "pivot_percents.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a44d9f-1cc5-45ef-b360-f4ae95b30e22",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b2274-32f6-473f-a8a5-3c355028c69a",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_4.png\" style=\"width:50%;\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1d75f-b6a4-48ea-b3a3-fc916f08b973",
   "metadata": {},
   "source": [
    "**This figure calculates the distribution of trends for all marine species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33400be-bb7b-4d2a-bfea-7eea321bef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_levels = ['Critically Endangered', 'Endangered', 'Extinct in the Wild']\n",
    "\n",
    "df_subset = df_combined[df_combined['Threat'].isin(threat_levels)]\n",
    "\n",
    "# Count rows by trend_title\n",
    "counts = df_subset.query(\"year_published == 2025\") \\\n",
    "    .groupby([\"country_name\",\"country_code\",\"category\"]) \\\n",
    "    .size() \\\n",
    "    .reset_index(name=\"count\")\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_4.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30f6c5-6c47-476d-aca8-2d6f67dac5da",
   "metadata": {},
   "source": [
    "## Figure 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7ec33-bf35-49da-ab0a-d063f6534528",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_5.png\" style=\"width:50%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a7c11-e677-46a9-8c6b-e0ad6a9d909e",
   "metadata": {},
   "source": [
    "**This figure shows the distribution of trend types by country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91ed1d-c45a-4b9e-9ad0-019a49761635",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df = df_combined.query(\"year_published==2025\")[['category','sis_taxon_id','country_name','country_code','trend_title']]\n",
    "trends_df.to_csv(\"../Data/protect_marine_life_2.csv\")\n",
    "\n",
    "# Count rows by trend_title and country\n",
    "counts = (\n",
    "    df_combined.query(\"year_published == 2025\")\n",
    "    .groupby([\"trend_title\", \"category\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Compute total counts per category\n",
    "category_totals = counts.groupby(\"category\")[\"count\"].transform(\"sum\")\n",
    "\n",
    "# Add percent within each category\n",
    "counts[\"percent\"] = counts[\"count\"] / category_totals * 100\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_5_by_species.json\", orient=\"records\", indent=2)\n",
    "\n",
    "# Count rows by trend_title and country\n",
    "counts = df_combined.query(\"year_published == 2025\") \\\n",
    "    .groupby([\"trend_title\"]) \\\n",
    "    .size() \\\n",
    "    .reset_index(name=\"count\")\n",
    "\n",
    "# Add percent within each country\n",
    "counts[\"percent\"] = counts[\"count\"] / counts[\"count\"].sum() * 100\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_5_all.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ba0b3-19c4-47bc-b7b6-99b38e38471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e9077-3eea-4088-9809-b08b3b32eb55",
   "metadata": {},
   "source": [
    "## Figures 6 and 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318b6ba-cd28-4380-8272-eca6d8c5104f",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_6.png\" style=\"width:50%;\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_8.png\" style=\"width:50%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b617d-2b17-4a54-bac1-c4b9aca12b20",
   "metadata": {},
   "source": [
    "**This code iterates through each species over time, and if a species does not have an assessment for a given year, it assigns that species-year combination the most recent assessment's threat for that species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e453e3-a55b-4c2b-9ef1-3096bf30addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map threat_code to Threat\n",
    "def map_threat(threat_code):\n",
    "    if threat_code.startswith('1_'):\n",
    "        return 'Residential & commercial development'\n",
    "    elif threat_code.startswith('2_'):\n",
    "        return 'Agriculture & aquaculture'\n",
    "    elif threat_code.startswith('3'):\n",
    "        return 'Energy production & mining'\n",
    "    elif threat_code.startswith('4_'):\n",
    "        return 'Transportation & service corridors'\n",
    "    elif threat_code.startswith('5_'):\n",
    "        return 'Biological resource use'\n",
    "    elif threat_code.startswith('6'):\n",
    "        return 'Human intrusions & disturbance'\n",
    "    elif threat_code.startswith('7_'):\n",
    "        return 'Natural system modifications'\n",
    "    elif threat_code.startswith('8_'):\n",
    "        return 'Invasive and other problematic species, genes & diseases'\n",
    "    elif threat_code.startswith('9_'):\n",
    "        return 'Pollution'\n",
    "    elif threat_code.startswith('10_'):\n",
    "        return 'Geological events'\n",
    "    elif threat_code.startswith('11_'):\n",
    "        return 'Climate change & severe weather'\n",
    "    elif threat_code.startswith('12_'):\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Unknown'  # for any other threat codes\n",
    "\n",
    "threats_df = pd.read_csv(\"../Data/all_threats_species.csv\")\n",
    "threats_df['year_published'] = threats_df['year_published'].astype(int)\n",
    "\n",
    "# Apply the function to create the new Threat column\n",
    "threats_df['Threat'] = threats_df['threat_code'].apply(map_threat)\n",
    "\n",
    "# Initialize an empty list to store new rows\n",
    "new_rows = []\n",
    "\n",
    "# Define the range of years\n",
    "years = range(1997, 2026)\n",
    "\n",
    "# Iterate through each sis_taxon_id\n",
    "for sis_taxon_id in tqdm(threats_df['sis_taxon_id'].unique()):\n",
    "    # Filter data for the current sis_taxon_id\n",
    "    df_sis = threats_df[threats_df['sis_taxon_id'] == sis_taxon_id]\n",
    "    \n",
    "    # Iterate through each year in the defined range\n",
    "    for year in years:\n",
    "        # Check if there is an entry for the current year\n",
    "        if year not in df_sis['year_published'].values:\n",
    "            # Find the most recent threat categorization from a previous year\n",
    "            previous_threats = df_sis[df_sis['year_published'] < year]\n",
    "            if not previous_threats.empty:\n",
    "                last_threat = previous_threats.iloc[-1]['Threat']\n",
    "                class_name = previous_threats.iloc[-1]['class_name']\n",
    "                country_code = previous_threats.iloc[-1]['country_code']\n",
    "                english_common_name = previous_threats.iloc[-1]['english_common_name']\n",
    "                # Create a new row with the current year, sis_taxon_id, and the most recent threat categorization\n",
    "                new_row = {\n",
    "                    'year_published': year,\n",
    "                    'Threat': last_threat,\n",
    "                    'sis_taxon_id': sis_taxon_id,\n",
    "                    'class_name': class_name,\n",
    "                    \"country_code\": country_code,\n",
    "                    \"english_common_name\": english_common_name,\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "# Create a DataFrame from the new rows\n",
    "df_new_rows = pd.DataFrame(new_rows)\n",
    "\n",
    "# Append the new rows to the original dataframe\n",
    "threats_combined = pd.concat([threats_df, df_new_rows])\n",
    "\n",
    "# Sort the combined dataframe\n",
    "threats_combined = threats_combined.sort_values(by=['sis_taxon_id', 'year_published']).reset_index(drop=True)\n",
    "\n",
    "# Map the class names to categories\n",
    "threats_combined['category'] = threats_combined['class_name'].map(class_to_category)\n",
    "\n",
    "# Apply the function to the country_code column\n",
    "threats_combined['country_name'] = threats_combined['country_code'].apply(get_country_name)\n",
    "\n",
    "threats_df = threats_combined.query(\"year_published==2024\")[['category','country_name','country_code','Threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0600b6e-7f68-448c-904d-c8f90417ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows by trend_title\n",
    "counts = threats_df \\\n",
    "    .groupby([\"Threat\",\"category\"]) \\\n",
    "    .size() \\\n",
    "    .reset_index(name=\"count\")\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_6.json\", orient=\"records\", indent=2)\n",
    "\n",
    "# Count rows by trend_title\n",
    "counts = threats_df \\\n",
    "    .groupby([\"country_name\",\"country_code\",\"Threat\",\"category\"]) \\\n",
    "    .size() \\\n",
    "    .reset_index(name=\"count\")\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_8.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0450f3b-67cd-44e9-9465-65130f35aad5",
   "metadata": {},
   "source": [
    "## Figures 7 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ad1c9-8ec7-4a2c-907e-93153664f99e",
   "metadata": {},
   "source": [
    "**This figure takes the most recent trends for each marine species and shows how they are distributed across countries globally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2cc14-a9ed-43e4-bb5d-01096a83b7e8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_7.png\" style=\"width:50%;\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_9.png\" style=\"width:50%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645303f-aea8-4c1d-b28e-3f9d4d928409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "trends_df = pd.read_csv(\"../Data/all_trends_species.csv\")\n",
    "trends_df = trends_df[[\"assessment_id\",\"sis_taxon_id\",\"year_published\",\"country_code\",\"status\",\"class_name\",\"english_common_name\",\"trend\"]]\n",
    "\n",
    "# Mapping dictionary\n",
    "threats_mapping = {\n",
    "    'DD': 'Data Deficient',\n",
    "    'LC': 'Least Concern',\n",
    "    'NT': 'Near Threatened',\n",
    "    'VU': 'Vulnerable',\n",
    "    'EN': 'Endangered',\n",
    "    'CR': 'Critically Endangered',\n",
    "    'EW': 'Extinct in the Wild',\n",
    "    'EX': 'Extinct',\n",
    "    'NE': 'Not Evaluated',\n",
    "}\n",
    "\n",
    "# Replace the values in the 'Threat' column\n",
    "trends_df['Threat'] = trends_df['status'].replace(threats_mapping)\n",
    "\n",
    "trends_df.loc[trends_df[\"trend\"] == 0, 'trend_title'] = \"Increasing\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 1, 'trend_title'] = \"Decreasing\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 2, 'trend_title'] = \"Stable\"\n",
    "trends_df.loc[trends_df[\"trend\"] == 3, 'trend_title'] = \"Unknown\"\n",
    "\n",
    "trends_df['year'] = trends_df['year_published']\n",
    "\n",
    "# Initialize an empty list to store new rows\n",
    "new_rows = []\n",
    "\n",
    "# Define the range of years\n",
    "years = range(1997, 2026)\n",
    "\n",
    "# Iterate through each sis_taxon_id\n",
    "for sis_taxon_id in tqdm(trends_df['sis_taxon_id'].unique()):\n",
    "    # Filter data for the current sis_taxon_id\n",
    "    df_sis = trends_df[trends_df['sis_taxon_id'] == sis_taxon_id]\n",
    "    \n",
    "    # Iterate through each year in the defined range\n",
    "    for year in years:\n",
    "        # Check if there is an entry for the current year\n",
    "        if year not in df_sis['year_published'].values:\n",
    "            # Find the most recent threat categorization from a previous year\n",
    "            previous_threats = df_sis[df_sis['year_published'] < year]\n",
    "            if not previous_threats.empty:\n",
    "                last_threat = previous_threats.iloc[-1]['Threat']\n",
    "                class_name = previous_threats.iloc[-1]['class_name']\n",
    "                country_code = previous_threats.iloc[-1]['country_code']\n",
    "                english_common_name = previous_threats.iloc[-1]['english_common_name']\n",
    "                trend_title = previous_threats.iloc[-1]['trend_title']\n",
    "                # Create a new row with the current year, sis_taxon_id, and the most recent threat categorization\n",
    "                new_row = {\n",
    "                    'year_published': previous_threats.iloc[-1]['year_published'],\n",
    "                    'year': year,\n",
    "                    'Threat': last_threat,\n",
    "                    'sis_taxon_id': sis_taxon_id,\n",
    "                    'class_name': class_name,\n",
    "                    \"country_code\": country_code,\n",
    "                    \"english_common_name\": english_common_name,\n",
    "                    \"trend_title\": trend_title,\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "# Create a DataFrame from the new rows\n",
    "df_new_rows = pd.DataFrame(new_rows)\n",
    "\n",
    "# Append the new rows to the original dataframe\n",
    "df_combined = pd.concat([trends_df, df_new_rows])\n",
    "\n",
    "# Sort the combined dataframe\n",
    "df_combined = df_combined.sort_values(by=['sis_taxon_id', 'year_published']).reset_index(drop=True)\n",
    "\n",
    "# Apply the function to the country_code column\n",
    "df_combined['country_name'] = df_combined['country_code'].apply(get_country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c765af2-bbe4-4061-8e75-0add68e6100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_combined.query(\"year_published == year\")\n",
    "\n",
    "# Define current year for relative calculations\n",
    "CURRENT_YEAR = 2025\n",
    "\n",
    "def classify_group(group):\n",
    "    years = pd.to_numeric(group[\"year_published\"], errors=\"coerce\").dropna().astype(int)\n",
    "    years = sorted(years.unique())  # still keep unique years for recency checks\n",
    "    n_rows = len(group)  # total rows for this assessment_id\n",
    "    \n",
    "    if n_rows == 0:\n",
    "        return \"Insufficient\"\n",
    "    \n",
    "    max_year = max(years) if years else None\n",
    "    if max_year is None or max_year < CURRENT_YEAR - 10:\n",
    "        return \"Expired\"\n",
    "    \n",
    "    has_recent = any(year >= CURRENT_YEAR - 7 for year in years)\n",
    "    has_stale = any(CURRENT_YEAR - 10 <= year <= CURRENT_YEAR - 8 for year in years)\n",
    "    \n",
    "    if has_recent and n_rows >= 2:   # use total number of rows instead of unique years\n",
    "        return \"Sufficient\"\n",
    "    elif has_recent:\n",
    "        return \"Recent\"\n",
    "    elif has_stale:\n",
    "        return \"Stale\"\n",
    "    else:\n",
    "        return \"Expired\"  # fallback\n",
    "\n",
    "# Apply per assessment_id\n",
    "classification = df.groupby(\"assessment_id\").apply(classify_group)\n",
    "\n",
    "# Merge back into dataframe\n",
    "df = df.merge(classification.rename(\"classification\"), \n",
    "              on=\"assessment_id\", how=\"left\")\n",
    "\n",
    "# Keep most recent entry for each assessment_id\n",
    "df = df.loc[df.groupby(\"assessment_id\")[\"year_published\"].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# Map classes to categories\n",
    "class_to_category = {\n",
    "    'ACTINOPTERYGII': 'Fish', \n",
    "    'CHONDRICHTHYES': 'Fish', \n",
    "    'SARCOPTERYGII': 'Fish', \n",
    "    'PETROMYZONTI': 'Fish',\n",
    "    'MYXINI': 'Fish',\n",
    "    'CEPHALASPIDOMORPHI': 'Fish',\n",
    "    'MAMMALIA': 'Mammals', \n",
    "    'REPTILIA': 'Reptiles', \n",
    "    'AVES': 'Birds'\n",
    "}\n",
    "df['category'] = df['class_name'].map(class_to_category)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc95a2-5f80-4de4-aaab-4a9994ff0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threats of interest\n",
    "threat_levels = ['Critically Endangered', 'Endangered', 'Extinct in the Wild']\n",
    "\n",
    "final_df = df[df['Threat'].isin(threat_levels)][['category','country_name','country_code','english_common_name','Threat','trend_title']]\n",
    "\n",
    "final_df.to_json(\"../Data/Figure_7.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679706f6-bacf-44c2-a9f4-969d04f3a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows by trend_title\n",
    "counts = final_df \\\n",
    "    .groupby([\"country_name\",\"country_code\",\"Threat\"]) \\\n",
    "    .size() \\\n",
    "    .reset_index(name=\"count\")\n",
    "\n",
    "# Save to JSON\n",
    "counts.to_json(\"../Data/Figure_9.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cd06c-109d-448e-9a2e-e3aa0a2360f5",
   "metadata": {},
   "source": [
    "## Ship Strikes Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ba257-65ff-44c5-aad6-611b27320af3",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Figs/marine_life_10.png\" style=\"width:50%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e841552-2586-4b7a-928a-193688f01b81",
   "metadata": {},
   "source": [
    "The data are derived from Table 7 of this [IWC report](https://www.researchgate.net/publication/342734400_Global_Numbers_of_Ship_Strikes_An_Assessment_of_Collisions_Between_Vessels_and_Cetaceans_Using_Available_Data_in_the_IWC_Ship_Strike_Database_Report_to_the_International_Whaling_Commission_IWC68BSC_HI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865e11f-5677-40d2-9738-4b72dbfc1f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claymodel",
   "language": "python",
   "name": "claymodel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
